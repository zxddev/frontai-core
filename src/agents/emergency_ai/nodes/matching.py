"""
é˜¶æ®µ3: èµ„æºåŒ¹é…èŠ‚ç‚¹

ä»æ•°æ®åº“æŸ¥è¯¢çœŸå®æ•‘æ´é˜Ÿä¼ï¼Œæ ¹æ®äº‹ä»¶åæ ‡è®¡ç®—è·ç¦»å’Œå“åº”æ—¶é—´ï¼Œ
æŒ‰æ—¶é—´çº¦æŸè¿‡æ»¤å¹¶è¿›è¡Œèƒ½åŠ›åŒ¹é…ã€‚
"""
from __future__ import annotations

import logging
import time
import uuid
from typing import Dict, Any, List, Optional, Tuple

from sqlalchemy import text
from sqlalchemy.ext.asyncio import AsyncSession

from src.core.database import AsyncSessionLocal
from ..state import EmergencyAIState, ResourceCandidate, AllocationSolution

logger = logging.getLogger(__name__)

# å¹³å‡æ•‘æ´è½¦è¾†è¡Œé©¶é€Ÿåº¦ï¼ˆkm/hï¼‰ï¼Œç”¨äºè®¡ç®—å“åº”æ—¶é—´
AVERAGE_SPEED_KMH: float = 40.0

# é»˜è®¤æœ€å¤§æœç´¢è·ç¦»ï¼ˆkmï¼‰
DEFAULT_MAX_DISTANCE_KM: float = 100.0

# æ‰©å¤§æœç´¢èŒƒå›´çš„æ­¥é•¿ï¼ˆkmï¼‰
DISTANCE_EXPAND_STEP_KM: float = 50.0

# æœ€å¤§æœç´¢è·ç¦»ä¸Šé™ï¼ˆkmï¼‰
MAX_SEARCH_DISTANCE_KM: float = 300.0

# é»˜è®¤é˜Ÿä¼æŸ¥è¯¢ä¸Šé™ï¼ˆæ”¯æŒå¤§è§„æ¨¡æ•‘æ´åœºæ™¯ï¼‰
DEFAULT_MAX_TEAMS: int = 200

# ç¾å®³ç­‰çº§å¯¹åº”çš„é˜Ÿä¼æ•°é‡ä¸Šé™
DISASTER_SCALE_LIMITS: Dict[str, int] = {
    "small": 50,      # å°å‹ç¾å®³ï¼ˆç¤¾åŒºçº§ï¼‰
    "medium": 100,    # ä¸­å‹ç¾å®³ï¼ˆåŒºå¿çº§ï¼‰
    "large": 200,     # å¤§å‹ç¾å®³ï¼ˆåŸå¸‚çº§ï¼‰
    "catastrophic": 500,  # ç‰¹å¤§ç¾å®³ï¼ˆåœ°éœ‡çº§ï¼‰
}


async def match_resources(state: EmergencyAIState) -> Dict[str, Any]:
    """
    èµ„æºåŒ¹é…èŠ‚ç‚¹ï¼šä»æ•°æ®åº“æŸ¥è¯¢çœŸå®é˜Ÿä¼å¹¶åŒ¹é…

    æ ¹æ®äº‹ä»¶åæ ‡ä»rescue_teams_v2è¡¨æŸ¥è¯¢å¯ç”¨é˜Ÿä¼ï¼Œ
    è®¡ç®—è·ç¦»å’Œå“åº”æ—¶é—´ï¼ŒæŒ‰èƒ½åŠ›éœ€æ±‚è¿›è¡ŒåŒ¹é…è¯„åˆ†ã€‚

    Args:
        state: å½“å‰çŠ¶æ€ï¼Œå¿…é¡»åŒ…å«structured_input.location

    Returns:
        æ›´æ–°çš„çŠ¶æ€å­—æ®µï¼ŒåŒ…å«resource_candidates

    Raises:
        ValueError: structured_input.locationç¼ºå¤±æˆ–æ— æ•ˆ
    """
    logger.info(f"[èµ„æºåŒ¹é…] å¼€å§‹æ‰§è¡Œï¼Œevent_id={state['event_id']}")
    start_time = time.time()

    errors: List[str] = list(state.get("errors", []))
    trace: Dict[str, Any] = dict(state.get("trace", {}))

    # è·å–äº‹ä»¶åæ ‡ï¼ˆå¿…é¡»ä»structured_inputè·å–ï¼‰
    event_location = _extract_event_location(state)
    if event_location is None:
        error_msg = "structured_input.locationç¼ºå¤±æˆ–æ— æ•ˆï¼Œå¿…é¡»æä¾›äº‹ä»¶åæ ‡(longitude/latitude)"
        logger.error(f"[èµ„æºåŒ¹é…] {error_msg}")
        errors.append(error_msg)
        return {
            "resource_candidates": [],
            "errors": errors,
            "trace": trace,
        }

    event_lat, event_lng = event_location
    logger.info(f"[èµ„æºåŒ¹é…] äº‹ä»¶åæ ‡: lat={event_lat}, lng={event_lng}")

    # è·å–èƒ½åŠ›éœ€æ±‚
    capability_requirements = state.get("capability_requirements", [])
    if not capability_requirements:
        logger.warning("[èµ„æºåŒ¹é…] æ— èƒ½åŠ›éœ€æ±‚ï¼Œè·³è¿‡èµ„æºåŒ¹é…")
        return {"resource_candidates": [], "trace": trace}

    required_caps = {cap["capability_code"] for cap in capability_requirements}
    logger.info(f"[èµ„æºåŒ¹é…] éœ€è¦çš„èƒ½åŠ›: {required_caps}")

    # è·å–çº¦æŸæ¡ä»¶
    constraints = state.get("constraints", {})
    
    # è·å–ç¾å®³ç­‰çº§å’Œé˜Ÿä¼æ•°é‡ä¸Šé™
    disaster_scale = _determine_disaster_scale(state)
    max_teams = constraints.get("max_teams", DISASTER_SCALE_LIMITS.get(disaster_scale, DEFAULT_MAX_TEAMS))
    logger.info(f"[èµ„æºåŒ¹é…] ç¾å®³ç­‰çº§: {disaster_scale}ï¼Œé˜Ÿä¼ä¸Šé™: {max_teams}")

    # è·å–æ—¶é—´çº¦æŸ
    max_response_hours = constraints.get("max_response_time_hours", 2.0)
    initial_max_distance = max_response_hours * AVERAGE_SPEED_KMH
    logger.info(f"[èµ„æºåŒ¹é…] æ—¶é—´çº¦æŸ: {max_response_hours}å°æ—¶ï¼Œåˆå§‹æœç´¢è·ç¦»: {initial_max_distance}km")

    # ä»æ•°æ®åº“æŸ¥è¯¢é˜Ÿä¼
    teams: List[Dict[str, Any]] = []
    search_distance = initial_max_distance
    search_expanded = False

    async with AsyncSessionLocal() as db:
        # ç¬¬ä¸€æ¬¡æŸ¥è¯¢ï¼šæŒ‰æ—¶é—´çº¦æŸèŒƒå›´
        teams = await _query_teams_from_db(
            db=db,
            event_lat=event_lat,
            event_lng=event_lng,
            max_distance_km=search_distance,
            max_teams=max_teams,
        )
        logger.info(f"[èµ„æºåŒ¹é…] åˆå§‹æŸ¥è¯¢: è·ç¦»<={search_distance}km, ä¸Šé™{max_teams}æ”¯, æ‰¾åˆ°{len(teams)}æ”¯é˜Ÿä¼")

        # æ£€æŸ¥èƒ½åŠ›è¦†ç›–
        covered_caps = _get_covered_capabilities(teams)
        missing_caps = required_caps - covered_caps

        # å¦‚æœèƒ½åŠ›è¦†ç›–ä¸è¶³ï¼Œæ‰©å¤§æœç´¢èŒƒå›´
        while missing_caps and search_distance < MAX_SEARCH_DISTANCE_KM:
            search_distance += DISTANCE_EXPAND_STEP_KM
            search_expanded = True
            logger.warning(
                f"[èµ„æºåŒ¹é…] èƒ½åŠ›è¦†ç›–ä¸è¶³ï¼Œç¼ºå¤±: {missing_caps}ï¼Œæ‰©å¤§æœç´¢èŒƒå›´è‡³{search_distance}km"
            )

            teams = await _query_teams_from_db(
                db=db,
                event_lat=event_lat,
                event_lng=event_lng,
                max_distance_km=search_distance,
                max_teams=max_teams,
            )
            covered_caps = _get_covered_capabilities(teams)
            missing_caps = required_caps - covered_caps

    if not teams:
        error_msg = f"åœ¨{search_distance}kmèŒƒå›´å†…æœªæ‰¾åˆ°ä»»ä½•å¯ç”¨é˜Ÿä¼"
        logger.error(f"[èµ„æºåŒ¹é…] {error_msg}")
        errors.append(error_msg)
        return {
            "resource_candidates": [],
            "errors": errors,
            "trace": trace,
        }

    # è®°å½•æœç´¢èŒƒå›´æ‰©å¤§çš„æƒ…å†µ
    if search_expanded:
        expand_msg = f"æœç´¢èŒƒå›´ä»{initial_max_distance}kmæ‰©å¤§è‡³{search_distance}kmä»¥è¦†ç›–æ‰€éœ€èƒ½åŠ›"
        logger.warning(f"[èµ„æºåŒ¹é…] {expand_msg}")
        trace["search_expanded"] = True
        trace["initial_distance_km"] = initial_max_distance
        trace["final_distance_km"] = search_distance

    # æ£€æŸ¥æœ€ç»ˆèƒ½åŠ›è¦†ç›–
    if missing_caps:
        missing_msg = f"ä»¥ä¸‹èƒ½åŠ›åœ¨{search_distance}kmèŒƒå›´å†…æ— é˜Ÿä¼å…·å¤‡: {missing_caps}"
        logger.warning(f"[èµ„æºåŒ¹é…] {missing_msg}")
        errors.append(missing_msg)
        trace["missing_capabilities"] = list(missing_caps)

    # è®¡ç®—åŒ¹é…åˆ†æ•°
    candidates = _calculate_match_scores(
        teams=teams,
        required_capabilities=required_caps,
        event_lat=event_lat,
        event_lng=event_lng,
        max_response_hours=max_response_hours,
    )

    # æŒ‰åŒ¹é…åˆ†æ•°æ’åº
    candidates.sort(key=lambda x: x["match_score"], reverse=True)

    # æ›´æ–°è¿½è¸ªä¿¡æ¯
    trace["phases_executed"] = trace.get("phases_executed", []) + ["match_resources"]
    trace["algorithms_used"] = trace.get("algorithms_used", []) + ["database_query", "capability_matching"]
    trace["teams_queried"] = len(teams)
    trace["candidates_count"] = len(candidates)

    elapsed_ms = int((time.time() - start_time) * 1000)
    logger.info(
        f"[èµ„æºåŒ¹é…] å®Œæˆï¼ŒæŸ¥è¯¢{len(teams)}æ”¯é˜Ÿä¼ï¼Œç”Ÿæˆ{len(candidates)}ä¸ªå€™é€‰ï¼Œè€—æ—¶{elapsed_ms}ms"
    )

    return {
        "resource_candidates": candidates,
        "trace": trace,
        "errors": errors,
        "current_phase": "matching",
    }


async def optimize_allocation(state: EmergencyAIState) -> Dict[str, Any]:
    """
    åˆ†é…ä¼˜åŒ–èŠ‚ç‚¹ï¼šåŸºäºå€™é€‰èµ„æºç”Ÿæˆå¤šä¸ªåˆ†é…æ–¹æ¡ˆ

    ä½¿ç”¨NSGA-IIå¤šç›®æ ‡ä¼˜åŒ–ç”ŸæˆParetoæœ€ä¼˜è§£é›†ã€‚
    å¦‚æœå€™é€‰èµ„æºè¾ƒå°‘ï¼ˆ<=10ï¼‰ï¼Œé€€åŒ–ä¸ºè´ªå¿ƒç­–ç•¥ä»¥æé«˜æ•ˆç‡ã€‚

    Args:
        state: å½“å‰çŠ¶æ€

    Returns:
        æ›´æ–°çš„çŠ¶æ€å­—æ®µï¼ŒåŒ…å«allocation_solutionså’Œpareto_solutions
    """
    logger.info(f"[åˆ†é…ä¼˜åŒ–] å¼€å§‹æ‰§è¡Œï¼Œevent_id={state['event_id']}")
    start_time = time.time()

    candidates = state.get("resource_candidates", [])
    capability_requirements = state.get("capability_requirements", [])
    task_sequence = state.get("task_sequence", [])  # HTNåˆ†è§£åçš„ä»»åŠ¡åºåˆ—
    constraints = state.get("constraints", {})
    trace: Dict[str, Any] = dict(state.get("trace", {}))
    errors: List[str] = list(state.get("errors", []))
    
    # è·å–è¢«å›°äººæ•°ç”¨äºè®¡ç®—æ•‘æ´å®¹é‡éœ€æ±‚
    parsed_disaster = state.get("parsed_disaster", {})
    estimated_trapped = parsed_disaster.get("estimated_trapped", 0) if parsed_disaster else 0
    logger.info(f"[åˆ†é…ä¼˜åŒ–] è¢«å›°äººæ•°: {estimated_trapped}")

    if not candidates:
        logger.warning("[åˆ†é…ä¼˜åŒ–] æ— å€™é€‰èµ„æºï¼Œæ— æ³•ç”Ÿæˆæ–¹æ¡ˆ")
        return {
            "allocation_solutions": [],
            "pareto_solutions": [],
            "trace": trace,
            "errors": errors,
        }

    # è·å–ç”Ÿæˆæ–¹æ¡ˆæ•°é‡
    n_alternatives = constraints.get("n_alternatives", 5)
    
    solutions: List[AllocationSolution] = []
    algorithm_used = "greedy"  # é»˜è®¤è´ªå¿ƒ

    # å°è¯•ä½¿ç”¨NSGA-IIï¼ˆå€™é€‰èµ„æº>10æ—¶æ•ˆæœæ›´å¥½ï¼‰
    if len(candidates) > 10:
        try:
            nsga_solutions = _run_nsga2_optimization(
                candidates=candidates,
                capability_requirements=capability_requirements,
                task_sequence=task_sequence,
                n_solutions=n_alternatives,
                estimated_trapped=estimated_trapped,
            )
            if nsga_solutions:
                solutions = nsga_solutions
                algorithm_used = "NSGA-II"
                logger.info(f"[åˆ†é…ä¼˜åŒ–] NSGA-IIç”Ÿæˆ{len(solutions)}ä¸ªParetoè§£")
        except Exception as e:
            logger.warning(f"[åˆ†é…ä¼˜åŒ–] NSGA-IIå¤±è´¥ï¼Œé€€åŒ–ä¸ºè´ªå¿ƒç­–ç•¥: {e}")
            errors.append(f"NSGA-IIä¼˜åŒ–å¤±è´¥: {e}")

    # å¦‚æœNSGA-IIæœªç”Ÿæˆæ–¹æ¡ˆï¼Œä½¿ç”¨è´ªå¿ƒç­–ç•¥
    if not solutions:
        # æ–¹æ¡ˆ1: æœ€é«˜åŒ¹é…åˆ†æ•°ä¼˜å…ˆ
        solution1 = _generate_greedy_solution(
            candidates=candidates,
            capability_requirements=capability_requirements,
            strategy="match_score",
            solution_id=f"solution-{uuid.uuid4().hex[:8]}",
            estimated_trapped=estimated_trapped,
        )
        if solution1:
            solutions.append(solution1)

        # æ–¹æ¡ˆ2: æœ€çŸ­å“åº”æ—¶é—´ä¼˜å…ˆï¼ˆæŒ‰è·ç¦»æ’åºï¼‰
        solution2 = _generate_greedy_solution(
            candidates=candidates,
            capability_requirements=capability_requirements,
            strategy="distance",
            solution_id=f"solution-{uuid.uuid4().hex[:8]}",
            estimated_trapped=estimated_trapped,
        )
        if solution2:
            solutions.append(solution2)

        # æ–¹æ¡ˆ3: æœ€é«˜å¯ç”¨æ€§ä¼˜å…ˆ
        solution3 = _generate_greedy_solution(
            candidates=candidates,
            capability_requirements=capability_requirements,
            strategy="availability",
            solution_id=f"solution-{uuid.uuid4().hex[:8]}",
            estimated_trapped=estimated_trapped,
        )
        if solution3:
            solutions.append(solution3)

    # Paretoæœ€ä¼˜è§£
    pareto_solutions = _deduplicate_solutions(solutions)[:n_alternatives]

    # æ›´æ–°è¿½è¸ªä¿¡æ¯
    trace["phases_executed"] = trace.get("phases_executed", []) + ["optimize_allocation"]
    trace["algorithms_used"] = trace.get("algorithms_used", []) + [algorithm_used]
    trace["solutions_generated"] = len(solutions)
    trace["optimization_algorithm"] = algorithm_used

    elapsed_ms = int((time.time() - start_time) * 1000)
    logger.info(
        f"[åˆ†é…ä¼˜åŒ–] å®Œæˆï¼Œç®—æ³•={algorithm_used}ï¼Œç”Ÿæˆ{len(solutions)}ä¸ªæ–¹æ¡ˆï¼ŒParetoè§£{len(pareto_solutions)}ä¸ªï¼Œè€—æ—¶{elapsed_ms}ms"
    )

    return {
        "allocation_solutions": solutions,
        "pareto_solutions": pareto_solutions,
        "trace": trace,
        "errors": errors,
    }


def _run_nsga2_optimization(
    candidates: List[ResourceCandidate],
    capability_requirements: List[Dict[str, Any]],
    task_sequence: List[Dict[str, Any]],
    n_solutions: int = 5,
    estimated_trapped: int = 0,
) -> List[AllocationSolution]:
    """
    ä½¿ç”¨NSGA-IIè¿›è¡Œå¤šç›®æ ‡ä¼˜åŒ–
    
    ä¼˜åŒ–ç›®æ ‡ï¼ˆ5ç»´è¯„ä¼°ï¼‰ï¼š
    1. æœ€å¤§åŒ–æˆåŠŸç‡ï¼ˆæƒé‡0.35ï¼‰
    2. æœ€å°åŒ–å“åº”æ—¶é—´ï¼ˆæƒé‡0.30ï¼‰
    3. æœ€å¤§åŒ–è¦†ç›–ç‡ï¼ˆæƒé‡0.20ï¼‰
    4. æœ€å°åŒ–é£é™©ï¼ˆæƒé‡0.05ï¼‰
    5. æœ€å¤§åŒ–å†—ä½™æ€§ï¼ˆæƒé‡0.10ï¼‰
    
    Args:
        candidates: å€™é€‰èµ„æº
        capability_requirements: èƒ½åŠ›éœ€æ±‚
        task_sequence: HTNä»»åŠ¡åºåˆ—
        n_solutions: ç”Ÿæˆæ–¹æ¡ˆæ•°é‡
        
    Returns:
        Paretoæœ€ä¼˜è§£åˆ—è¡¨
    """
    logger.info(f"[NSGA-II] å¼€å§‹å¤šç›®æ ‡ä¼˜åŒ–")
    logger.info(f"  - å€™é€‰èµ„æºæ•°: {len(candidates)}")
    logger.info(f"  - èƒ½åŠ›éœ€æ±‚æ•°: {len(capability_requirements)}")
    logger.info(f"  - ä»»åŠ¡åºåˆ—é•¿åº¦: {len(task_sequence)}")
    logger.info(f"  - ç›®æ ‡è§£æ•°é‡: {n_solutions}")
    
    try:
        from pymoo.algorithms.moo.nsga2 import NSGA2
        from pymoo.operators.crossover.sbx import SBX
        from pymoo.operators.mutation.pm import PM
        from pymoo.operators.sampling.rnd import BinaryRandomSampling
        from pymoo.optimize import minimize
        from pymoo.core.problem import Problem
        import numpy as np
        logger.info(f"[NSGA-II] pymooåº“å¯¼å…¥æˆåŠŸ")
    except ImportError:
        logger.warning("[NSGA-II] pymooæœªå®‰è£…ï¼Œä½¿ç”¨è´ªå¿ƒç­–ç•¥")
        raise ImportError("pymoo not installed")

    required_caps = {cap["capability_code"] for cap in capability_requirements}
    n_resources = len(candidates)
    logger.info(f"[NSGA-II] éœ€æ±‚èƒ½åŠ›: {required_caps}")
    
    if n_resources == 0:
        logger.warning("[NSGA-II] æ— å€™é€‰èµ„æºï¼Œè¿”å›ç©º")
        return []

    class EmergencyAllocationProblem(Problem):
        """åº”æ€¥èµ„æºåˆ†é…é—®é¢˜å®šä¹‰"""
        
        def __init__(self):
            # å†³ç­–å˜é‡ï¼šæ¯ä¸ªå€™é€‰èµ„æºæ˜¯å¦é€‰ä¸­ï¼ˆ0/1ï¼‰
            super().__init__(
                n_var=n_resources,
                n_obj=3,  # å“åº”æ—¶é—´ã€è¦†ç›–ç‡ã€é˜Ÿä¼æ•°é‡ï¼ˆæˆæœ¬ä»£ç†ï¼‰
                n_constr=1,  # è‡³å°‘è¦†ç›–70%èƒ½åŠ›
                xl=0,
                xu=1,
                vtype=int,
            )
        
        def _evaluate(self, X, out, *args, **kwargs):
            F = []  # ç›®æ ‡å‡½æ•°å€¼
            G = []  # çº¦æŸå‡½æ•°å€¼
            
            for x in X:
                selected_indices = np.where(x > 0.5)[0]
                
                if len(selected_indices) == 0:
                    # æ— é€‰ä¸­èµ„æºï¼Œæƒ©ç½š
                    F.append([1000, 0, 1000])
                    G.append([1.0])  # è¿åçº¦æŸ
                    continue
                
                # è®¡ç®—å“åº”æ—¶é—´ï¼ˆæœ€å¤§ETAï¼‰
                max_eta = 0.0
                covered_caps: set = set()
                total_score = 0.0
                
                for idx in selected_indices:
                    cand = candidates[idx]
                    max_eta = max(max_eta, cand.get("eta_minutes", 0))
                    covered_caps.update(cand["capabilities"])
                    total_score += cand["match_score"]
                
                # è¦†ç›–ç‡ï¼ˆè´Ÿå€¼å› ä¸ºè¦æœ€å¤§åŒ–ï¼‰
                coverage = len(covered_caps.intersection(required_caps)) / len(required_caps) if required_caps else 1.0
                
                # ç›®æ ‡ï¼šå“åº”æ—¶é—´ï¼ˆæœ€å°åŒ–ï¼‰ã€-è¦†ç›–ç‡ï¼ˆæœ€å°åŒ–ä»¥æœ€å¤§åŒ–è¦†ç›–ï¼‰ã€é˜Ÿä¼æ•°é‡ï¼ˆæœ€å°åŒ–æˆæœ¬ï¼‰
                F.append([max_eta, -coverage, len(selected_indices)])
                
                # çº¦æŸï¼šè¦†ç›–ç‡>=70%
                G.append([0.7 - coverage])
            
            out["F"] = np.array(F)
            out["G"] = np.array(G)

    problem = EmergencyAllocationProblem()
    
    logger.info(f"[NSGA-II] é…ç½®ç®—æ³•å‚æ•°:")
    logger.info(f"  - pop_size: 50 (ç§ç¾¤å¤§å°)")
    logger.info(f"  - n_gen: 50 (è¿­ä»£ä»£æ•°)")
    logger.info(f"  - n_var: {n_resources} (å†³ç­–å˜é‡æ•°)")
    logger.info(f"  - n_obj: 3 (ç›®æ ‡æ•°: å“åº”æ—¶é—´/è¦†ç›–ç‡/é˜Ÿä¼æ•°)")
    logger.info(f"  - n_constr: 1 (çº¦æŸ: è¦†ç›–ç‡>=70%)")
    
    algorithm = NSGA2(
        pop_size=50,
        sampling=BinaryRandomSampling(),
        crossover=SBX(prob=0.9, eta=15),
        mutation=PM(eta=20),
        eliminate_duplicates=True,
    )
    
    logger.info(f"[NSGA-II] å¼€å§‹ä¼˜åŒ–è¿­ä»£...")
    import time as time_module
    start_opt = time_module.time()
    
    result = minimize(
        problem,
        algorithm,
        termination=("n_gen", 50),
        seed=42,
        verbose=False,
    )
    
    elapsed_opt = int((time_module.time() - start_opt) * 1000)
    logger.info(f"[NSGA-II] ä¼˜åŒ–å®Œæˆï¼Œè€—æ—¶{elapsed_opt}ms")
    
    if result.X is None or len(result.X) == 0:
        logger.warning("[NSGA-II] æ— å¯è¡Œè§£")
        return []
    
    logger.info(f"[NSGA-II] æ‰¾åˆ°Paretoå‰æ²¿è§£")
    
    # è½¬æ¢ä¸ºAllocationSolution
    solutions: List[AllocationSolution] = []
    seen_solutions: set = set()
    
    # å¤„ç†ç»“æœï¼ˆå¯èƒ½æ˜¯å•è§£æˆ–å¤šè§£ï¼‰
    X_array = result.X if len(result.X.shape) == 2 else [result.X]
    F_array = result.F if len(result.F.shape) == 2 else [result.F]
    
    for sol_idx, (x, f) in enumerate(zip(X_array, F_array)):
        selected_indices = np.where(x > 0.5)[0]
        if len(selected_indices) == 0:
            continue
        
        # å»é‡
        sol_key = frozenset(int(i) for i in selected_indices)
        if sol_key in seen_solutions:
            continue
        seen_solutions.add(sol_key)
        
        # æ„å»ºåˆ†é…æ–¹æ¡ˆ
        allocations: List[Dict[str, Any]] = []
        covered_caps: set = set()
        max_eta = 0.0
        max_distance = 0.0
        total_capacity = 0
        
        for idx in selected_indices:
            cand = candidates[int(idx)]
            assignable_caps = set(cand["capabilities"]).intersection(required_caps) - covered_caps
            cand_capacity = cand.get("rescue_capacity", 0)
            
            allocations.append({
                "resource_id": cand["resource_id"],
                "resource_name": cand["resource_name"],
                "resource_type": cand["resource_type"],
                "assigned_capabilities": list(assignable_caps) if assignable_caps else cand["capabilities"],
                "match_score": cand["match_score"],
                "distance_km": cand["distance_km"],
                "eta_minutes": cand.get("eta_minutes", 0),
                "rescue_capacity": cand_capacity,
            })
            covered_caps.update(cand["capabilities"])
            max_eta = max(max_eta, cand.get("eta_minutes", 0))
            max_distance = max(max_distance, cand["distance_km"])
            total_capacity += cand_capacity
        
        coverage_rate = len(covered_caps.intersection(required_caps)) / len(required_caps) if required_caps else 1.0
        avg_score = sum(a["match_score"] for a in allocations) / len(allocations) if allocations else 0
        uncovered = required_caps - covered_caps
        
        # è®¡ç®—å®¹é‡è¦†ç›–ç‡å’Œè­¦å‘Š
        capacity_coverage = total_capacity / estimated_trapped if estimated_trapped > 0 else 1.0
        capacity_warning: Optional[str] = None
        if estimated_trapped > 0:
            capacity_gap = estimated_trapped - total_capacity
            if capacity_coverage < 0.5:
                capacity_warning = f"ğŸš¨ æ•‘æ´å®¹é‡ä¸¥é‡ä¸è¶³ï¼è¢«å›°{estimated_trapped}äººï¼Œæ€»å®¹é‡{total_capacity}äººï¼ˆè¦†ç›–ç‡{capacity_coverage*100:.1f}%ï¼‰ï¼Œç¼ºå£{capacity_gap}äºº"
            elif capacity_coverage < 0.8:
                capacity_warning = f"âš ï¸ æ•‘æ´å®¹é‡ä¸è¶³ï¼è¢«å›°{estimated_trapped}äººï¼Œæ€»å®¹é‡{total_capacity}äººï¼ˆè¦†ç›–ç‡{capacity_coverage*100:.1f}%ï¼‰ï¼Œç¼ºå£{capacity_gap}äºº"
        
        solution: AllocationSolution = {
            "solution_id": f"nsga-{uuid.uuid4().hex[:8]}",
            "allocations": allocations,
            "total_score": round(avg_score, 3),
            "response_time_min": round(max_eta, 1),
            "coverage_rate": round(coverage_rate, 3),
            "resource_scale": len(allocations),
            "risk_level": round(1.0 - coverage_rate, 3),
            "total_rescue_capacity": total_capacity,
            "capacity_coverage_rate": round(capacity_coverage, 3),
            "capacity_warning": capacity_warning,
            "uncovered_capabilities": list(uncovered) if uncovered else [],
            "max_distance_km": round(max_distance, 2),
            "teams_count": len(allocations),
            "objectives": {
                "response_time": round(float(f[0]), 1),
                "coverage_rate": round(-float(f[1]), 3),
                "teams_count": int(f[2]),
            },
        }
        solutions.append(solution)
        
        if len(solutions) >= n_solutions:
            break
    
    # æŒ‰è¦†ç›–ç‡é™åºæ’åº
    solutions.sort(key=lambda s: s["coverage_rate"], reverse=True)
    
    return solutions


def _extract_event_location(state: EmergencyAIState) -> Optional[Tuple[float, float]]:
    """
    ä»stateä¸­æå–äº‹ä»¶åæ ‡

    ä¼˜å…ˆä»structured_input.locationè·å–ï¼Œ
    æ”¯æŒ{longitude, latitude}æˆ–{lng, lat}æ ¼å¼ã€‚

    Returns:
        (latitude, longitude)å…ƒç»„ï¼Œæˆ–Noneè¡¨ç¤ºæ— æ•ˆ
    """
    structured_input = state.get("structured_input", {})
    if not structured_input:
        return None

    location = structured_input.get("location", {})
    if not location:
        return None

    # æ”¯æŒå¤šç§å­—æ®µå
    lat = location.get("latitude") or location.get("lat")
    lng = location.get("longitude") or location.get("lng")

    if lat is None or lng is None:
        return None

    try:
        lat_float = float(lat)
        lng_float = float(lng)
        # åŸºæœ¬æœ‰æ•ˆæ€§æ£€æŸ¥
        if not (-90 <= lat_float <= 90 and -180 <= lng_float <= 180):
            return None
        return (lat_float, lng_float)
    except (TypeError, ValueError):
        return None


def _determine_disaster_scale(state: EmergencyAIState) -> str:
    """
    æ ¹æ®ç¾æƒ…åˆ¤æ–­ç¾å®³ç­‰çº§
    
    Args:
        state: å½“å‰çŠ¶æ€
        
    Returns:
        ç¾å®³ç­‰çº§: small/medium/large/catastrophic
    """
    parsed_disaster = state.get("parsed_disaster")
    if parsed_disaster is None:
        logger.info("[åŒ¹é…-ç¾å®³ç­‰çº§] æ— ç¾æƒ…æ•°æ®ï¼Œä½¿ç”¨é»˜è®¤ç­‰çº§: medium")
        return "medium"
    
    # æ ¹æ®å—å½±å“äººå£åˆ¤æ–­
    affected_pop = parsed_disaster.get("affected_population", 0)
    estimated_trapped = parsed_disaster.get("estimated_trapped", 0)
    severity = parsed_disaster.get("severity", "medium")
    disaster_type = parsed_disaster.get("disaster_type", "").lower()
    
    logger.info(f"[åŒ¹é…-ç¾å®³ç­‰çº§] åˆ¤æ–­è¾“å…¥å‚æ•°:")
    logger.info(f"  - disaster_type: {disaster_type}")
    logger.info(f"  - severity: {severity}")
    logger.info(f"  - affected_population: {affected_pop}")
    logger.info(f"  - estimated_trapped: {estimated_trapped}")
    
    # åœ°éœ‡/ç‰¹å¤§ç¾å®³
    if disaster_type == "earthquake" or severity == "critical":
        if affected_pop > 10000 or estimated_trapped > 100:
            logger.info(f"[åŒ¹é…-ç¾å®³ç­‰çº§] åˆ¤æ–­: åœ°éœ‡/ç‰¹å¤§ç¾å®³ + (äººå£>{10000}æˆ–è¢«å›°>{100}) -> catastrophic")
            return "catastrophic"
        logger.info(f"[åŒ¹é…-ç¾å®³ç­‰çº§] åˆ¤æ–­: åœ°éœ‡/ä¸¥é‡ç¾å®³ -> large")
        return "large"
    
    # æ ¹æ®è¢«å›°äººæ•°
    if estimated_trapped > 50:
        logger.info(f"[åŒ¹é…-ç¾å®³ç­‰çº§] åˆ¤æ–­: è¢«å›°äººæ•°{estimated_trapped} > 50 -> large")
        return "large"
    elif estimated_trapped > 10:
        logger.info(f"[åŒ¹é…-ç¾å®³ç­‰çº§] åˆ¤æ–­: è¢«å›°äººæ•°{estimated_trapped} > 10 -> medium")
        return "medium"
    
    # æ ¹æ®ä¸¥é‡ç¨‹åº¦
    severity_mapping = {
        "critical": "large",
        "high": "medium",
        "medium": "medium",
        "low": "small",
    }
    result = severity_mapping.get(severity, "medium")
    logger.info(f"[åŒ¹é…-ç¾å®³ç­‰çº§] åˆ¤æ–­: æŒ‰ä¸¥é‡ç¨‹åº¦{severity} -> {result}")
    return result


async def _query_teams_from_db(
    db: AsyncSession,
    event_lat: float,
    event_lng: float,
    max_distance_km: float,
    max_teams: int = DEFAULT_MAX_TEAMS,
) -> List[Dict[str, Any]]:
    """
    ä»æ•°æ®åº“æŸ¥è¯¢æŒ‡å®šèŒƒå›´å†…çš„å¯ç”¨é˜Ÿä¼

    ä½¿ç”¨PostGIS ST_Distanceè®¡ç®—çƒé¢è·ç¦»ï¼Œ
    å…³è”team_capabilities_v2è·å–èƒ½åŠ›åˆ—è¡¨ã€‚

    Args:
        db: æ•°æ®åº“ä¼šè¯
        event_lat: äº‹ä»¶çº¬åº¦
        event_lng: äº‹ä»¶ç»åº¦
        max_distance_km: æœ€å¤§è·ç¦»ï¼ˆå…¬é‡Œï¼‰
        max_teams: è¿”å›çš„æœ€å¤§é˜Ÿä¼æ•°é‡

    Returns:
        é˜Ÿä¼åˆ—è¡¨ï¼Œæ¯ä¸ªé˜Ÿä¼åŒ…å«id, name, type, capabilities, distance_mç­‰
    """
    sql = text("""
        SELECT 
            t.id,
            t.code,
            t.name,
            t.team_type,
            ST_Y(t.base_location::geometry) AS base_lat,
            ST_X(t.base_location::geometry) AS base_lng,
            t.base_address,
            t.total_personnel,
            t.available_personnel,
            t.capability_level,
            t.response_time_minutes,
            t.status,
            COALESCE(
                ARRAY_AGG(DISTINCT tc.capability_code) 
                FILTER (WHERE tc.capability_code IS NOT NULL),
                ARRAY[]::VARCHAR[]
            ) AS capabilities,
            COALESCE(SUM(tc.max_capacity), 0) AS total_rescue_capacity,
            ST_Distance(
                t.base_location,
                ST_SetSRID(ST_MakePoint(:event_lng, :event_lat), 4326)::geography
            ) AS distance_m
        FROM operational_v2.rescue_teams_v2 t
        LEFT JOIN operational_v2.team_capabilities_v2 tc ON tc.team_id = t.id
        WHERE t.status = 'standby'
          AND t.base_location IS NOT NULL
          AND ST_Distance(
                t.base_location,
                ST_SetSRID(ST_MakePoint(:event_lng, :event_lat), 4326)::geography
              ) <= :max_distance_m
        GROUP BY t.id
        ORDER BY distance_m ASC, t.capability_level DESC
        LIMIT :max_teams
    """)

    params = {
        "event_lat": event_lat,
        "event_lng": event_lng,
        "max_distance_m": max_distance_km * 1000,
        "max_teams": max_teams,
    }

    try:
        result = await db.execute(sql, params)
        rows = result.fetchall()
        columns = result.keys()

        teams: List[Dict[str, Any]] = []
        for row in rows:
            row_dict = dict(zip(columns, row))
            
            # æ•‘æ´å®¹é‡ï¼šä¼˜å…ˆä½¿ç”¨æ•°æ®åº“å€¼ï¼Œå¦åˆ™æŒ‰ç±»å‹ä¼°ç®—
            db_capacity = row_dict.get("total_rescue_capacity", 0) or 0
            team_type = row_dict["team_type"]
            available = row_dict["available_personnel"] or 0
            
            if db_capacity > 0:
                rescue_capacity = int(db_capacity)
            else:
                # æŒ‰é˜Ÿä¼ç±»å‹ä¼°ç®—æ•‘æ´å®¹é‡ï¼ˆ72å°æ—¶å†…å¯æ•‘æ´äººæ•°ï¼‰
                capacity_multipliers = {
                    "fire_rescue": 2.0,       # æ¶ˆé˜²é˜Ÿæ¯äººå¯æ•‘2äºº
                    "search_rescue": 1.5,     # æœæ•‘é˜Ÿæ¯äººå¯æ•‘1.5äºº
                    "medical": 5.0,           # åŒ»ç–—é˜Ÿæ¯äººå¯å¤„ç†5ä¼¤å‘˜
                    "hazmat": 0.5,            # å±åŒ–å“é˜Ÿä¸ç›´æ¥æ•‘äºº
                    "engineering": 0.0,       # å·¥ç¨‹é˜Ÿä¸ç›´æ¥æ•‘äºº
                    "volunteer": 1.0,         # å¿—æ„¿è€…æ¯äººå¯æ•‘1äºº
                }
                multiplier = capacity_multipliers.get(team_type, 1.0)
                rescue_capacity = int(available * multiplier)
                if rescue_capacity == 0 and available > 0:
                    rescue_capacity = available  # å…œåº•ï¼šè‡³å°‘ç­‰äºå¯ç”¨äººæ•°
                logger.debug(f"[æ•‘æ´å®¹é‡ä¼°ç®—] {row_dict['name']} æ— max_capacityï¼ŒæŒ‰ç±»å‹{team_type}ä¼°ç®—: {available}äººÃ—{multiplier}={rescue_capacity}")
            
            team = {
                "id": str(row_dict["id"]),
                "code": row_dict["code"],
                "name": row_dict["name"],
                "team_type": row_dict["team_type"],
                "base_lat": row_dict["base_lat"],
                "base_lng": row_dict["base_lng"],
                "base_address": row_dict["base_address"],
                "total_personnel": row_dict["total_personnel"],
                "available_personnel": row_dict["available_personnel"],
                "capability_level": row_dict["capability_level"],
                "response_time_minutes": row_dict["response_time_minutes"],
                "status": row_dict["status"],
                "capabilities": list(row_dict["capabilities"] or []),
                "distance_m": row_dict["distance_m"],
                "distance_km": row_dict["distance_m"] / 1000.0 if row_dict["distance_m"] else 0,
                "rescue_capacity": rescue_capacity,
            }
            teams.append(team)

        total_capacity = sum(t["rescue_capacity"] for t in teams)
        logger.info(f"[æ•°æ®åº“æŸ¥è¯¢] æŸ¥è¯¢åˆ°{len(teams)}æ”¯é˜Ÿä¼ï¼Œæ€»æ•‘æ´å®¹é‡{total_capacity}äºº")
        return teams

    except Exception as e:
        logger.error(f"[æ•°æ®åº“æŸ¥è¯¢] æŸ¥è¯¢é˜Ÿä¼å¤±è´¥: {e}")
        raise


def _get_covered_capabilities(teams: List[Dict[str, Any]]) -> set:
    """è·å–æ‰€æœ‰é˜Ÿä¼è¦†ç›–çš„èƒ½åŠ›é›†åˆ"""
    covered: set = set()
    for team in teams:
        covered.update(team.get("capabilities", []))
    return covered


def _calculate_match_scores(
    teams: List[Dict[str, Any]],
    required_capabilities: set,
    event_lat: float,
    event_lng: float,
    max_response_hours: float,
) -> List[ResourceCandidate]:
    """
    è®¡ç®—æ¯ä¸ªé˜Ÿä¼çš„åŒ¹é…åˆ†æ•°

    è¯„åˆ†ç»´åº¦ï¼š
    - èƒ½åŠ›è¦†ç›–ç‡ï¼ˆ50%ï¼‰ï¼šé˜Ÿä¼èƒ½åŠ›ä¸éœ€æ±‚çš„äº¤é›†æ¯”ä¾‹
    - è·ç¦»è¯„åˆ†ï¼ˆ30%ï¼‰ï¼šè·ç¦»è¶Šè¿‘åˆ†æ•°è¶Šé«˜
    - èƒ½åŠ›ç­‰çº§ï¼ˆ20%ï¼‰ï¼šcapability_levelè¶Šé«˜åˆ†æ•°è¶Šé«˜

    Args:
        teams: é˜Ÿä¼åˆ—è¡¨
        required_capabilities: éœ€è¦çš„èƒ½åŠ›é›†åˆ
        event_lat: äº‹ä»¶çº¬åº¦
        event_lng: äº‹ä»¶ç»åº¦
        max_response_hours: æœ€å¤§å“åº”æ—¶é—´ï¼ˆå°æ—¶ï¼‰

    Returns:
        ResourceCandidateåˆ—è¡¨
    """
    candidates: List[ResourceCandidate] = []
    max_distance_km = max_response_hours * AVERAGE_SPEED_KMH

    for team in teams:
        team_caps = set(team.get("capabilities", []))
        matched_caps = team_caps.intersection(required_capabilities)

        # æ— åŒ¹é…èƒ½åŠ›åˆ™è·³è¿‡
        if not matched_caps:
            continue

        # èƒ½åŠ›è¦†ç›–ç‡è¯„åˆ†
        capability_score = len(matched_caps) / len(required_capabilities) if required_capabilities else 0

        # è·ç¦»è¯„åˆ†ï¼ˆè·ç¦»è¶Šè¿‘è¶Šå¥½ï¼‰
        distance_km = team.get("distance_km", 0)
        distance_score = max(0, 1.0 - distance_km / max_distance_km) if max_distance_km > 0 else 0

        # èƒ½åŠ›ç­‰çº§è¯„åˆ†ï¼ˆ1-5æ˜ å°„åˆ°0.2-1.0ï¼‰
        capability_level = team.get("capability_level", 3)
        level_score = capability_level / 5.0

        # è®¡ç®—å“åº”æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰
        eta_minutes = (distance_km / AVERAGE_SPEED_KMH) * 60 if distance_km > 0 else 0

        # ç»¼åˆå¾—åˆ†
        match_score = (
            capability_score * 0.50 +
            distance_score * 0.30 +
            level_score * 0.20
        )

        # é˜Ÿä¼ç±»å‹æ˜ å°„
        resource_type = _map_team_type(team.get("team_type", ""))

        candidate: ResourceCandidate = {
            "resource_id": team["id"],
            "resource_name": team["name"],
            "resource_type": resource_type,
            "capabilities": list(matched_caps),
            "distance_km": round(distance_km, 2),
            "availability_score": 1.0,  # æ•°æ®åº“æŸ¥è¯¢å·²è¿‡æ»¤standbyçŠ¶æ€
            "match_score": round(match_score, 3),
            "rescue_capacity": team.get("rescue_capacity", 0),  # æ•‘æ´å®¹é‡
            # æ‰©å±•å­—æ®µ
            "eta_minutes": round(eta_minutes, 1),
            "capability_level": capability_level,
            "base_address": team.get("base_address", ""),
            "personnel": team.get("available_personnel") or team.get("total_personnel", 0),
        }
        candidates.append(candidate)

    return candidates


def _map_team_type(team_type: str) -> str:
    """é˜Ÿä¼ç±»å‹æ˜ å°„åˆ°æ ‡å‡†èµ„æºç±»å‹"""
    mapping = {
        "fire_rescue": "FIRE_TEAM",
        "medical": "MEDICAL_TEAM",
        "search_rescue": "RESCUE_TEAM",
        "hazmat": "HAZMAT_TEAM",
        "engineering": "ENGINEERING_TEAM",
        "communication": "SUPPORT_TEAM",
        "logistics": "SUPPORT_TEAM",
        "water_rescue": "WATER_RESCUE_TEAM",
        "mountain_rescue": "RESCUE_TEAM",
        "mine_rescue": "RESCUE_TEAM",
        "armed_police": "ARMED_TEAM",
        "evacuation": "EVACUATION_TEAM",
        "volunteer": "VOLUNTEER_TEAM",
    }
    return mapping.get(team_type, "RESCUE_TEAM")


def _generate_greedy_solution(
    candidates: List[ResourceCandidate],
    capability_requirements: List[Dict[str, Any]],
    strategy: str,
    solution_id: str,
    estimated_trapped: int = 0,
) -> Optional[AllocationSolution]:
    """
    ä½¿ç”¨è´ªå¿ƒç­–ç•¥ç”Ÿæˆåˆ†é…æ–¹æ¡ˆ
    
    ä¿®å¤ç‰ˆæœ¬ï¼šåŒæ—¶è€ƒè™‘èƒ½åŠ›è¦†ç›–å’Œæ•‘æ´å®¹é‡ï¼Œä¸ä¼šåœ¨èƒ½åŠ›è¦†ç›–100%æ—¶å°±åœæ­¢

    Args:
        candidates: å€™é€‰èµ„æºåˆ—è¡¨
        capability_requirements: èƒ½åŠ›éœ€æ±‚åˆ—è¡¨
        strategy: ç­–ç•¥ (match_score/distance/availability)
        solution_id: æ–¹æ¡ˆID
        estimated_trapped: è¢«å›°äººæ•°ï¼Œç”¨äºè®¡ç®—æœ€ä½æ•‘æ´å®¹é‡éœ€æ±‚

    Returns:
        åˆ†é…æ–¹æ¡ˆæˆ–None
    """
    if not candidates or not capability_requirements:
        return None

    # æŒ‰ç­–ç•¥æ’åº
    if strategy == "match_score":
        sorted_candidates = sorted(candidates, key=lambda x: x["match_score"], reverse=True)
    elif strategy == "distance":
        sorted_candidates = sorted(candidates, key=lambda x: x["distance_km"])
    elif strategy == "availability":
        sorted_candidates = sorted(candidates, key=lambda x: x["availability_score"], reverse=True)
    else:
        sorted_candidates = list(candidates)

    # è®¡ç®—æœ€ä½æ•‘æ´å®¹é‡éœ€æ±‚ï¼ˆè¢«å›°äººæ•°çš„80%ï¼‰
    min_capacity_required = int(estimated_trapped * 0.8) if estimated_trapped > 0 else 0
    logger.info(f"[è´ªå¿ƒ-å®¹é‡] è¢«å›°äººæ•°={estimated_trapped}ï¼Œæœ€ä½å®¹é‡éœ€æ±‚={min_capacity_required}")

    # è´ªå¿ƒåˆ†é…
    required_caps = {cap["capability_code"] for cap in capability_requirements}
    covered_caps: set = set()
    allocations: List[Dict[str, Any]] = []
    max_eta = 0.0
    total_distance = 0.0
    total_capacity = 0  # ç´¯è®¡æ•‘æ´å®¹é‡
    capability_covered = False  # æ ‡è®°èƒ½åŠ›æ˜¯å¦å·²å…¨è¦†ç›–
    selected_ids: set = set()  # å·²é€‰æ‹©çš„é˜Ÿä¼IDï¼Œé¿å…é‡å¤

    for candidate in sorted_candidates:
        if candidate["resource_id"] in selected_ids:
            continue
            
        candidate_caps = set(candidate["capabilities"])
        new_caps = candidate_caps - covered_caps
        assignable_caps = new_caps.intersection(required_caps)
        candidate_capacity = candidate.get("rescue_capacity", 0)

        # å†³ç­–é€»è¾‘ï¼š
        # 1. å¦‚æœæœ‰æ–°èƒ½åŠ›å¯è¦†ç›–ï¼Œå¿…é¡»é€‰æ‹©
        # 2. å¦‚æœèƒ½åŠ›å·²å…¨è¦†ç›–ä½†å®¹é‡ä¸è¶³ï¼Œä¹Ÿè¦é€‰æ‹©ï¼ˆåªè¦æœ‰æ•‘æ´å®¹é‡ï¼‰
        should_select = False
        select_reason = ""
        
        if assignable_caps:
            should_select = True
            select_reason = f"æ–°å¢èƒ½åŠ›{assignable_caps}"
        elif capability_covered and total_capacity < min_capacity_required and candidate_capacity > 0:
            should_select = True
            select_reason = f"å®¹é‡ä¸è¶³({total_capacity}<{min_capacity_required})ï¼Œå¢åŠ å®¹é‡{candidate_capacity}"

        if should_select:
            # å®¹é‡è¡¥å……é˜Ÿä¼ï¼šä½¿ç”¨é˜Ÿä¼ä¸éœ€æ±‚çš„äº¤é›†èƒ½åŠ›ï¼ˆè€Œéç©ºåˆ—è¡¨ï¼‰
            effective_caps = assignable_caps if assignable_caps else candidate_caps.intersection(required_caps)
            allocations.append({
                "resource_id": candidate["resource_id"],
                "resource_name": candidate["resource_name"],
                "resource_type": candidate["resource_type"],
                "assigned_capabilities": list(effective_caps),
                "match_score": candidate["match_score"],
                "distance_km": candidate["distance_km"],
                "eta_minutes": candidate.get("eta_minutes", 0),
                "rescue_capacity": candidate_capacity,
            })
            selected_ids.add(candidate["resource_id"])
            covered_caps.update(assignable_caps)
            max_eta = max(max_eta, candidate.get("eta_minutes", 0))
            total_distance = max(total_distance, candidate["distance_km"])
            total_capacity += candidate_capacity
            
            logger.debug(f"[è´ªå¿ƒ-é€‰æ‹©] {candidate['resource_name']}: {select_reason}ï¼Œç´¯è®¡å®¹é‡={total_capacity}")

        # æ£€æŸ¥èƒ½åŠ›æ˜¯å¦å…¨è¦†ç›–
        if covered_caps.issuperset(required_caps):
            if not capability_covered:
                logger.info(f"[è´ªå¿ƒ-èƒ½åŠ›] èƒ½åŠ›å·²å…¨è¦†ç›–ï¼Œå½“å‰å®¹é‡={total_capacity}ï¼Œéœ€æ±‚={min_capacity_required}")
            capability_covered = True
            
            # ç»ˆæ­¢æ¡ä»¶ï¼šèƒ½åŠ›å…¨è¦†ç›– AND å®¹é‡è¶³å¤Ÿ
            if estimated_trapped == 0 or total_capacity >= min_capacity_required:
                logger.info(f"[è´ªå¿ƒ-å®Œæˆ] èƒ½åŠ›è¦†ç›–100%ä¸”å®¹é‡è¶³å¤Ÿï¼Œæ€»å®¹é‡={total_capacity}")
                break

    if not allocations:
        return None
    
    # === å†—ä½™æ€§å¢å¼ºé˜¶æ®µ ===
    # ç»Ÿè®¡æ¯ä¸ªèƒ½åŠ›è¢«å¤šå°‘é˜Ÿä¼è¦†ç›–
    capability_coverage_count: Dict[str, int] = {cap: 0 for cap in required_caps}
    for alloc in allocations:
        for cap in alloc.get("assigned_capabilities", []):
            if cap in capability_coverage_count:
                capability_coverage_count[cap] += 1
    
    # æ‰¾å‡ºä½å†—ä½™èƒ½åŠ›ï¼ˆåªæœ‰1ä¸ªé˜Ÿä¼è¦†ç›–ï¼‰
    low_redundancy_caps = {cap for cap, count in capability_coverage_count.items() if count <= 1}
    
    if low_redundancy_caps:
        logger.info(f"[è´ªå¿ƒ-å†—ä½™] ä½å†—ä½™èƒ½åŠ›: {low_redundancy_caps}ï¼Œå°è¯•å¢åŠ å¤‡ä»½é˜Ÿä¼")
        
        # æœ€å¤šé¢å¤–æ·»åŠ 2æ”¯é˜Ÿä¼æé«˜å†—ä½™æ€§
        max_redundancy_teams = 2
        added_for_redundancy = 0
        
        for candidate in sorted_candidates:
            if added_for_redundancy >= max_redundancy_teams:
                break
            if candidate["resource_id"] in selected_ids:
                continue
            
            candidate_caps = set(candidate["capabilities"])
            # æ£€æŸ¥æ˜¯å¦èƒ½ä¸ºä½å†—ä½™èƒ½åŠ›æä¾›å¤‡ä»½
            can_backup = candidate_caps.intersection(low_redundancy_caps)
            
            if can_backup:
                allocations.append({
                    "resource_id": candidate["resource_id"],
                    "resource_name": candidate["resource_name"],
                    "resource_type": candidate["resource_type"],
                    "assigned_capabilities": list(can_backup),
                    "match_score": candidate["match_score"],
                    "distance_km": candidate["distance_km"],
                    "eta_minutes": candidate.get("eta_minutes", 0),
                    "rescue_capacity": candidate.get("rescue_capacity", 0),
                })
                selected_ids.add(candidate["resource_id"])
                total_capacity += candidate.get("rescue_capacity", 0)
                max_eta = max(max_eta, candidate.get("eta_minutes", 0))
                total_distance = max(total_distance, candidate["distance_km"])
                added_for_redundancy += 1
                
                # æ›´æ–°è¦†ç›–è®¡æ•°
                for cap in can_backup:
                    capability_coverage_count[cap] += 1
                
                # é‡æ–°è®¡ç®—ä½å†—ä½™èƒ½åŠ›
                low_redundancy_caps = {cap for cap, count in capability_coverage_count.items() if count <= 1}
                
                logger.info(f"[è´ªå¿ƒ-å†—ä½™] æ·»åŠ å¤‡ä»½é˜Ÿä¼: {candidate['resource_name']}ï¼Œä¸ºèƒ½åŠ›{can_backup}æä¾›å¤‡ä»½")
        
        if added_for_redundancy > 0:
            logger.info(f"[è´ªå¿ƒ-å†—ä½™] å†—ä½™å¢å¼ºå®Œæˆï¼Œé¢å¤–æ·»åŠ {added_for_redundancy}æ”¯é˜Ÿä¼")

    if not allocations:
        return None

    # è®¡ç®—æ–¹æ¡ˆæŒ‡æ ‡
    coverage_rate = len(covered_caps.intersection(required_caps)) / len(required_caps) if required_caps else 1.0
    avg_score = sum(a["match_score"] for a in allocations) / len(allocations)
    capacity_coverage = total_capacity / estimated_trapped if estimated_trapped > 0 else 1.0

    # æœªè¦†ç›–çš„èƒ½åŠ›
    uncovered = required_caps - covered_caps
    
    # ç”Ÿæˆå®¹é‡è­¦å‘Šï¼ˆåˆ†çº§ï¼‰
    capacity_warning: Optional[str] = None
    if estimated_trapped > 0:
        capacity_gap = estimated_trapped - total_capacity
        if capacity_coverage < 0.5:
            # ä¸¥é‡ä¸è¶³ï¼šè¦†ç›–ç‡<50%
            capacity_warning = (
                f"ğŸš¨ æ•‘æ´å®¹é‡ä¸¥é‡ä¸è¶³ï¼è¢«å›°{estimated_trapped}äººï¼Œ"
                f"æ´¾å‡ºé˜Ÿä¼æ€»å®¹é‡ä»…{total_capacity}äººï¼ˆè¦†ç›–ç‡{capacity_coverage*100:.1f}%ï¼‰ï¼Œ"
                f"ç¼ºå£{capacity_gap}äººã€‚å¿…é¡»ç´§æ€¥è¯·æ±‚å›½å®¶çº§å¢æ´ï¼"
            )
            logger.error(f"[è´ªå¿ƒ-ä¸¥é‡è­¦å‘Š] {capacity_warning}")
        elif capacity_coverage < 0.8:
            # ä¸è¶³ï¼šè¦†ç›–ç‡50%-80%
            capacity_warning = (
                f"âš ï¸ æ•‘æ´å®¹é‡ä¸è¶³ï¼è¢«å›°{estimated_trapped}äººï¼Œ"
                f"æ´¾å‡ºé˜Ÿä¼æ€»å®¹é‡{total_capacity}äººï¼ˆè¦†ç›–ç‡{capacity_coverage*100:.1f}%ï¼‰ï¼Œ"
                f"ç¼ºå£{capacity_gap}äººã€‚å»ºè®®ç´§æ€¥è¯·æ±‚çœçº§å¢æ´ï¼"
            )
            logger.warning(f"[è´ªå¿ƒ-è­¦å‘Š] {capacity_warning}")
        elif capacity_coverage < 1.0:
            # è½»åº¦ä¸è¶³ï¼šè¦†ç›–ç‡80%-100%
            capacity_warning = (
                f"âš  æ•‘æ´å®¹é‡å­˜åœ¨ç¼ºå£ã€‚è¢«å›°{estimated_trapped}äººï¼Œ"
                f"æ´¾å‡ºé˜Ÿä¼æ€»å®¹é‡{total_capacity}äººï¼ˆè¦†ç›–ç‡{capacity_coverage*100:.1f}%ï¼‰ï¼Œ"
                f"ç¼ºå£{capacity_gap}äººã€‚å»ºè®®ç”³è¯·é¢å¤–å¢æ´ä»¥ç¡®ä¿å…¨å‘˜è·æ•‘ã€‚"
            )
            logger.warning(f"[è´ªå¿ƒ-æç¤º] {capacity_warning}")

    solution: AllocationSolution = {
        "solution_id": solution_id,
        "allocations": allocations,
        "total_score": round(avg_score, 3),
        "response_time_min": round(max_eta, 1),
        "coverage_rate": round(coverage_rate, 3),
        "resource_scale": len(allocations),
        "risk_level": round(1.0 - coverage_rate, 3),
        "total_rescue_capacity": total_capacity,
        "capacity_coverage_rate": round(capacity_coverage, 3),
        "capacity_warning": capacity_warning,
        # æ‰©å±•å­—æ®µ
        "uncovered_capabilities": list(uncovered) if uncovered else [],
        "max_distance_km": round(total_distance, 2),
        "teams_count": len(allocations),
    }

    return solution


def _deduplicate_solutions(solutions: List[AllocationSolution]) -> List[AllocationSolution]:
    """å»é‡æ–¹æ¡ˆï¼ˆåŸºäºåˆ†é…çš„é˜Ÿä¼IDé›†åˆï¼‰"""
    seen: set = set()
    unique: List[AllocationSolution] = []

    for sol in solutions:
        team_ids = frozenset(a["resource_id"] for a in sol["allocations"])
        if team_ids not in seen:
            seen.add(team_ids)
            unique.append(sol)

    return unique
